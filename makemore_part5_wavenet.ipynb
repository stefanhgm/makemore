{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mEF05xtbHwp"
      },
      "source": [
        "## makemore: part 5 (building a WaveNet)\n",
        "\n",
        "[DeepMind blog post from 2016](https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7lDFibCgbHwr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Takeways:\n",
        "# 1. Smoothen the loss curve by averaging over multiple steps\n",
        "#   - With small batch size, the loss curve very noisy due to BatchNorm\n",
        "# 2. PyTorchify the code\n",
        "#   - Put every operation into a PyTorch layer, i.e. encapsulate embedding and flatten into separate \"layers\"\n",
        "#   - Introduce PyTorch containers, i.e. introduce a Sequential container applying a list of layers\n",
        "# 3. Introduce WaveNet\n",
        "#   - Since training and validation loss similar, sense that not overfitting so bigger architecutre might be beneficial\n",
        "#   - Architecture is fusing neighboring inputs, e.g. two characters into bigram representation and bigram representations into fourgram etc.\n",
        "#   - Understanding higher dimensional batches to process clusters of characters in parallel and resctructure input with view\n",
        "#   - Implement new FlattenConsecutive layer flattening the input while preserving groups of inputs\n",
        "#   - Add new hidden layers in between to cater for concatenated characters\n",
        "# 4. Fix BatchNorm Bug (assumes only two dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# performance log\n",
        "# - original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n",
        "# - context: 3 -> 8 (22K params): train 1.918, val 2.027\n",
        "# - flat -> hierarchical (22K params): train 1.941, val 2.029 (after step 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "htdQCnUPbhS9"
      },
      "outputs": [],
      "source": [
        "# download the names.txt file from github\n",
        "# !wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ylW9Ir3GbHws",
        "outputId": "0c874340-2a0f-4d12-fcb0-2035564cebf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
          ]
        }
      ],
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GPwi-_rEbHwt",
        "outputId": "237fb410-4940-448b-a00b-0ab334f768e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "j8JdduA3bHwu"
      },
      "outputs": [],
      "source": [
        "# shuffle up the words\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kcrfsUG_bHwu",
        "outputId": "4d05c8d0-9d1f-4b1e-dfdb-db2becfe8afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9aFDMks6bHwv",
        "outputId": "2bb77886-1172-4b43-f446-b2e990e549aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "... --> y\n",
            "..y --> u\n",
            ".yu --> h\n",
            "yuh --> e\n",
            "uhe --> n\n",
            "hen --> g\n",
            "eng --> .\n",
            "... --> d\n",
            "..d --> i\n",
            ".di --> o\n",
            "dio --> n\n",
            "ion --> d\n",
            "ond --> r\n",
            "ndr --> e\n",
            "dre --> .\n",
            "... --> x\n",
            "..x --> a\n",
            ".xa --> v\n",
            "xav --> i\n",
            "avi --> e\n"
          ]
        }
      ],
      "source": [
        "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
        "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()]) # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-goFZmrabHww"
      },
      "outputs": [],
      "source": [
        "# Near copy paste of the layers we have developed in Part 3\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Linear:\n",
        "\n",
        "  def __init__(self, fan_in, fan_out, bias=True):\n",
        "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
        "    self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x @ self.weight\n",
        "    if self.bias is not None:\n",
        "      self.out += self.bias\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class BatchNorm1d:\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # parameters (trained with backprop)\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # buffers (trained with a running 'momentum update')\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    if self.training:\n",
        "      xmean = x.mean(0, keepdim=True) # batch mean\n",
        "      xvar = x.var(0, keepdim=True) # batch variance\n",
        "    else:\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    # update the buffers\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Tanh:\n",
        "  def __call__(self, x):\n",
        "    self.out = torch.tanh(x)\n",
        "    return self.out\n",
        "  def parameters(self):\n",
        "    return []\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Embedding:\n",
        "  \n",
        "  def __init__(self, num_embeddings, embedding_dim): \n",
        "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = self.weight[x] # for a batch of input sequences lookup weights, 2d to 3d tensor\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.weight]\n",
        "    \n",
        "# -----------------------------------------------------------------------------------------------\n",
        "class Flatten:\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    self.out = x.view(x.shape[0], -1) # flatten back into 2d of original size, i.e. lookups per input in the sequence are concatenated\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return []\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Introduce Sequential container to apply layers sequentially\n",
        "\n",
        "class Sequential:\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers: \n",
        "      x = layer(x)\n",
        "    self.out = x\n",
        "    return self.out\n",
        "    \n",
        "  def parameters(self):\n",
        "    # get parameters of all layers and strech them out into one list\n",
        "    return [p for layer in self.layers for p in layer.parameters()]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "v01gpFOSbHwx"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42); # seed rng for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "vHMDMtvpbHwx",
        "outputId": "dbb414a9-5753-4f41-c545-34957779b09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12097\n"
          ]
        }
      ],
      "source": [
        "# original network\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "model = Sequential([\n",
        "  Embedding(vocab_size, n_embd),\n",
        "  Flatten(),\n",
        "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Sh9SEATabHwy",
        "outputId": "4238b680-4e09-4da1-a52f-5153a4119ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0/ 200000: 3.2966\n",
            "  10000/ 200000: 2.2322\n",
            "  20000/ 200000: 2.4111\n",
            "  30000/ 200000: 2.1004\n",
            "  40000/ 200000: 2.3157\n",
            "  50000/ 200000: 2.2104\n",
            "  60000/ 200000: 1.9653\n",
            "  70000/ 200000: 1.9767\n",
            "  80000/ 200000: 2.6738\n",
            "  90000/ 200000: 2.0837\n",
            " 100000/ 200000: 2.2730\n",
            " 110000/ 200000: 1.7491\n",
            " 120000/ 200000: 2.2891\n",
            " 130000/ 200000: 2.3443\n",
            " 140000/ 200000: 2.1731\n",
            " 150000/ 200000: 1.8246\n",
            " 160000/ 200000: 1.7614\n",
            " 170000/ 200000: 2.2418\n",
            " 180000/ 200000: 2.0803\n",
            " 190000/ 200000: 2.1326\n"
          ]
        }
      ],
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  loss = F.cross_entropy(logits, Yb)\n",
        "  \n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "  # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x1580f9a80>]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Take average of loss over 1000 steps  - trick: reshape tensor then take mean over dim 1\n",
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))\n",
        "\n",
        "# Observe much smoother training loss curve\n",
        "# There is a step decay probably due to the learning rate drop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ehknU7xtbHwz"
      },
      "outputs": [],
      "source": [
        "# put layers into eval mode (needed for batchnorm especially)\n",
        "for layer in model.layers:\n",
        "  layer.training = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5W1wFpKubHwz",
        "outputId": "a965238b-34f8-42de-e6d6-3777a6837cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 2.0583250522613525\n",
            "val 2.1065292358398438\n"
          ]
        }
      ],
      "source": [
        "# evaluate the loss\n",
        "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  logits = model(x)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CSE5ZEgebHw0",
        "outputId": "b8f5baf1-143e-4fd6-8e14-cc1d1bd3a0b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zoevbsxzsqdfspfmsxnrgwdhisymoyeeoik.\n",
            "zunsnqykfxqszzhotbfcstekpltoomdlptiqd.\n",
            "msrqf.\n",
            "yieywsk.\n",
            "cmbxaodcveh.\n",
            "qktw.\n",
            "ildgagth.\n",
            "bggkbrnuzxczvuvtmljbvlhhchthiepypuasomofgejsdlrkoddtitkkc.\n",
            "unhnmpmixzfkturwcwdds.\n",
            ".\n",
            "adsjiabsvpyrqwbagxjr.\n",
            "btuvmnotchwma.\n",
            "dmtz.\n",
            "wwpjvln.\n",
            "uhllzndmbvlzpaaabkpvtrhseskeujffqubitvoupgujoyshgd.\n",
            ".\n",
            "bbswvfjwdfybqiywqykludrtgyajlwcmheowfzvxfvg.\n",
            "frieyqtftrrxl.\n",
            "umgtthrjjjunmnfksexehbztvagnwevamk.\n",
            "ztapjxssfwcqvrpdloqepmptrooqtvkunwcrr.\n"
          ]
        }
      ],
      "source": [
        "# sample from the model\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass the neural net\n",
        "      logits = model(torch.tensor([context]))\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1).item()\n",
        "      # shift the context window and track the samples\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      # if we sample the special '.' token, break\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Part 3: Code from above with WaveNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0, 14,  1, 20,  8],\n",
              "        [ 0,  0, 13,  1,  4,  9, 19, 15],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  1],\n",
              "        [ 0,  0,  0,  0,  0,  0,  1, 21]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Understand parallel processing of higher dimensional batches\n",
        "# - assume example with 8 characters input block size\n",
        "ix = torch. randint(0, Xtr.shape[0], (4,)) # let's look at a batch of just 4 examples\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "logits = model(Xb)\n",
        "print (Xb. shape)\n",
        "Xb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 10])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[0].out.shape # output of Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 80])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[1].out.shape # output of Flatten layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[2].out.shape # output of Linear layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Simulate process in linear layer\n",
        "# Input of batch of 4 ex, with 8 characters and 10 dimensional embedding\n",
        "(torch.randn(4, 80) @ torch.randn(80, 200) + torch.randn(200)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 5, 200])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Also possible to process higher dimensional batch, linear layer simply broadcasted (or shared across instances)\n",
        "(torch.randn(4, 5, 80) @ torch.randn(80, 200) + torch.randn(200)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 5, 6, 200])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(torch.randn(4, 5, 6, 80) @ torch.randn(80, 200) + torch.randn(200)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 4, 200])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Especially relevant for groups of characters: (1 2) (3 4) (5 6) (7 8)\n",
        "# Here batches would become something like: batch of 4 ex, with four subbatches of 4 character groups and 10 dimensional embedding (linear layer reused)\n",
        "(torch.randn(4, 4, 20) @ torch.randn(20, 200) + torch.randn(200)).shape\n",
        "\n",
        "# Takeaways: Change flatten layer to output (4, 4, 20) instead of (4, 80) and change linear layer to 20 input dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 4, 20])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# First try to implement this new flatten layer\n",
        "e = torch.rand(4, 8, 10) # goal: want this to be (4, 4, 20) where consecutive 10-d vectors get concatenated\n",
        "# Currently done\n",
        "e.view(4, -1).shape # (4, 80)\n",
        "# Concat even and odd parts for (1 2) (3 4) (5 6) (7 8)\n",
        "torch.cat([e[:, ::2, :], e[:, 1::2, :]], dim=2).shape # (4, 4, 20)\n",
        "# Simpler and more efficient\n",
        "e.view(4, 4, 20) # also works here due to arrangement of the inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([182625, 8]) torch.Size([182625])\n",
            "torch.Size([22655, 8]) torch.Size([22655])\n",
            "torch.Size([22866, 8]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "........ --> y\n",
            ".......y --> u\n",
            "......yu --> h\n",
            ".....yuh --> e\n",
            "....yuhe --> n\n",
            "...yuhen --> g\n",
            "..yuheng --> .\n",
            "........ --> d\n",
            ".......d --> i\n",
            "......di --> o\n",
            ".....dio --> n\n",
            "....dion --> d\n",
            "...diond --> r\n",
            "..diondr --> e\n",
            ".diondre --> .\n",
            "........ --> x\n",
            ".......x --> a\n",
            "......xa --> v\n",
            ".....xav --> i\n",
            "....xavi --> e\n"
          ]
        }
      ],
      "source": [
        "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
        "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()]) # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Only add new layers here\n",
        "class FlattenConsecutive:\n",
        "\n",
        "  def __init__(self, n):\n",
        "    self.n = n\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    # Make explicit to simplify\n",
        "    B, T, C = x.shape\n",
        "    x = x.view(B, T//self.n, C*self.n) # ensure that n characters / inputs are grouped into an embedding\n",
        "    # If no grouping use, i.e. second dimension 1, squeeze it\n",
        "    if x.shape[1] == 1:\n",
        "      x = x.squeeze(1)\n",
        "    self.out = x\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return []\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Fixed version for multiple dimensions\n",
        "class BatchNorm1d:\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # parameters (trained with backprop)\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # buffers (trained with a running 'momentum update')\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    if self.training:\n",
        "      # Determine mean and variance over all batch dimensions\n",
        "      dims = tuple(range(x.ndim - 1))\n",
        "      xmean = x.mean(dims, keepdim=True) # batch mean\n",
        "      xvar = x.var(dims, keepdim=True) # batch variance\n",
        "    else:\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    # update the buffers\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(42); # seed rng for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22397\n"
          ]
        }
      ],
      "source": [
        "# original network\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 68 # the number of neurons in the hidden layer of the MLP\n",
        "n_cons = 2 # the number of characters to combine\n",
        "\n",
        "# Corresponds to Figure 3 in https://arxiv.org/pdf/1609.03499 (with one less hidden layer using 16 input characters)\n",
        "model = Sequential([\n",
        "  Embedding(vocab_size, n_embd),\n",
        "  FlattenConsecutive(n_cons),\n",
        "  Linear(n_embd * n_cons, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  FlattenConsecutive(n_cons),\n",
        "  Linear(n_hidden * n_cons, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  FlattenConsecutive(n_cons),\n",
        "  Linear(n_hidden * n_cons, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(n_hidden, vocab_size),\n",
        "])\n",
        "\n",
        "# parameter init\n",
        "with torch.no_grad():\n",
        "  model.layers[-1].weight *= 0.1 # last layer make less confident\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "mean() received an invalid combination of arguments - got (range, keepdim=bool), but expected one of:\n * (*, torch.dtype dtype = None)\n      didn't match because some of the keywords were incorrect: keepdim\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[115], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m Xb, Yb \u001b[38;5;241m=\u001b[39m Xtr[ix], Ytr[ix]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (Xb\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Xb\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39m layers:\n",
            "Cell \u001b[0;32mIn[41], line 94\u001b[0m, in \u001b[0;36mSequential.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers: \n\u001b[0;32m---> 94\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     96\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\n",
            "Cell \u001b[0;32mIn[112], line 39\u001b[0m, in \u001b[0;36mBatchNorm1d.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;66;03m# calculate the forward pass\u001b[39;00m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Determine mean and variance over all batch dimensions\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     xmean \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# batch mean\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     xvar \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mvar(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, x\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# batch variance\u001b[39;00m\n\u001b[1;32m     41\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (range, keepdim=bool), but expected one of:\n * (*, torch.dtype dtype = None)\n      didn't match because some of the keywords were incorrect: keepdim\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n"
          ]
        }
      ],
      "source": [
        "# Lets debug for some input\n",
        "ix = torch.randint (0, Xtr.shape[0], (4,)) # let's look at a batch of just 4 examples\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "print (Xb.shape)\n",
        "logits = model(Xb)\n",
        "\n",
        "# Xb\n",
        "for layer in model. layers:\n",
        "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 2, 400])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fl = FlattenConsecutive(n_cons)\n",
        "fl(torch.randn(4, 4, 200)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0/ 200000: 3.2824\n",
            "  10000/ 200000: 2.0426\n",
            "  20000/ 200000: 1.9114\n",
            "  30000/ 200000: 2.2687\n",
            "  40000/ 200000: 2.2697\n",
            "  50000/ 200000: 1.7491\n",
            "  60000/ 200000: 2.2745\n",
            "  70000/ 200000: 1.9558\n",
            "  80000/ 200000: 1.9214\n",
            "  90000/ 200000: 2.0890\n",
            " 100000/ 200000: 1.8990\n",
            " 110000/ 200000: 2.0510\n",
            " 120000/ 200000: 2.2194\n",
            " 130000/ 200000: 1.9276\n",
            " 140000/ 200000: 1.8325\n",
            " 150000/ 200000: 2.0659\n",
            " 160000/ 200000: 2.1112\n",
            " 170000/ 200000: 1.8990\n",
            " 180000/ 200000: 1.3996\n",
            " 190000/ 200000: 2.2061\n"
          ]
        }
      ],
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  loss = F.cross_entropy(logits, Yb)\n",
        "  \n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update: simple SGD\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "  # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w054JOpbHw1"
      },
      "source": [
        "### Next time:\n",
        "Why convolutions? Brief preview/hint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBP4pbSnbHw1",
        "outputId": "5dc847b5-d40b-4e6a-f25b-55eedc770b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "........ --> d\n",
            ".......d --> i\n",
            "......di --> o\n",
            ".....dio --> n\n",
            "....dion --> d\n",
            "...diond --> r\n",
            "..diondr --> e\n",
            ".diondre --> .\n"
          ]
        }
      ],
      "source": [
        "for x,y in zip(Xtr[7:15], Ytr[7:15]):\n",
        "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhUwWXX8bHw2",
        "outputId": "9d5d20ce-180c-4178-fd22-3e7a7dcc38ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 27])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# forward a single example:\n",
        "logits = model(Xtr[[7]])\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBDyYGUWbHw2",
        "outputId": "f288231e-6a20-4940-845f-596944950912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 27])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# forward all of them\n",
        "logits = torch.zeros(8, 27)\n",
        "for i in range(8):\n",
        "  logits[i] = model(Xtr[[7+i]])\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCoo_TvZbHw3"
      },
      "outputs": [],
      "source": [
        "# convolution is a \"for loop\"\n",
        "# allows us to forward Linear layers efficiently over space"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "makemore",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
